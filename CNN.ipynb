{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cocodataset.org/#download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T01:06:33.195159Z",
     "start_time": "2019-11-22T01:06:20.436743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from cv2 import filter2D\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T01:06:33.765554Z",
     "start_time": "2019-11-22T01:06:33.197157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images =  5100\n"
     ]
    }
   ],
   "source": [
    "ids = next(os.walk(\"data/images\"))[2] # list of names all images in the given path\n",
    "ids_m = next(os.walk(\"data/masks\"))[2] # list of names all images in the given path\n",
    "# ids = ids[:1000]\n",
    "# ids_m = ids_m[:1000]\n",
    "\n",
    "print(\"No. of images = \", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:10:23.550096Z",
     "start_time": "2019-11-22T02:10:23.546003Z"
    }
   },
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:10:23.754093Z",
     "start_time": "2019-11-22T02:10:23.747112Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:12:37.591227Z",
     "start_time": "2019-11-22T02:10:25.229325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46588370bbfb475c9b32407fa4521baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5100), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "kernel = -1 * np.ones((kernel_size, kernel_size))\n",
    "kernel[kernel_size // 2 + 1, kernel_size// 2 + 1] = kernel_size ** 2 - 1\n",
    "\n",
    "for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "    img = load_img(\"data/images/\"+id_, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (im_width, im_height, 1), mode = 'constant', preserve_range = True)\n",
    "    # Load masks\n",
    "    mask = img_to_array(load_img(\"data/masks/\"+ id_[:-4] + '.png', color_mode = \"grayscale\"))\n",
    "    mask = filter2D(mask[...,0] , -1, kernel)\n",
    "    mask = resize(mask, (im_width, im_height, 1), mode = 'constant', preserve_range = True)\n",
    "    mask[mask!=0] = 1\n",
    "    X[n] = x_img/255.0\n",
    "    y[n] = mask/255.0\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T01:09:51.888404Z",
     "start_time": "2019-11-22T01:09:51.881422Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T01:09:51.908349Z",
     "start_time": "2019-11-22T01:09:51.890398Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T01:32:07.720864Z",
     "start_time": "2019-11-22T01:32:07.715878Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:46:29.394709Z",
     "start_time": "2019-11-22T02:46:29.389735Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_bce(y_true, y_pred):\n",
    "    weights = (y_true * 2.) + 1.\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_bce = K.mean(bce * weights)\n",
    "    return weighted_bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:46:47.510308Z",
     "start_time": "2019-11-22T02:46:46.352052Z"
    }
   },
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.01, batchnorm=True)\n",
    "\n",
    "# model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=Adam(), loss=weighted_bce, metrics=[\"accuracy\"])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:46:48.411395Z",
     "start_time": "2019-11-22T02:46:48.406410Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=0),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=0),\n",
    "    ModelCheckpoint('model_weighted_1.h5', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T02:56:37.908551Z",
     "start_time": "2019-11-22T02:46:50.949871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4590 samples, validate on 510 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680/4590 [=======================>......] - ETA: 22:34 - loss: 1.0496 - accuracy: 0.189 - ETA: 12:27 - loss: 1.0276 - accuracy: 0.195 - ETA: 9:04 - loss: 1.0059 - accuracy: 0.194 - ETA: 7:23 - loss: 0.9859 - accuracy: 0.19 - ETA: 6:21 - loss: 0.9608 - accuracy: 0.20 - ETA: 5:40 - loss: 0.9359 - accuracy: 0.22 - ETA: 5:10 - loss: 0.9121 - accuracy: 0.24 - ETA: 4:48 - loss: 0.8879 - accuracy: 0.26 - ETA: 4:30 - loss: 0.8654 - accuracy: 0.28 - ETA: 4:16 - loss: 0.8450 - accuracy: 0.30 - ETA: 4:05 - loss: 0.8260 - accuracy: 0.32 - ETA: 3:55 - loss: 0.8074 - accuracy: 0.34 - ETA: 3:46 - loss: 0.7974 - accuracy: 0.35 - ETA: 3:39 - loss: 0.7860 - accuracy: 0.37 - ETA: 3:33 - loss: 0.7742 - accuracy: 0.38 - ETA: 3:27 - loss: 0.7626 - accuracy: 0.39 - ETA: 3:22 - loss: 0.7494 - accuracy: 0.41 - ETA: 3:17 - loss: 0.7377 - accuracy: 0.42 - ETA: 3:13 - loss: 0.7265 - accuracy: 0.44 - ETA: 3:09 - loss: 0.7162 - accuracy: 0.45 - ETA: 3:06 - loss: 0.7064 - accuracy: 0.46 - ETA: 3:03 - loss: 0.6966 - accuracy: 0.47 - ETA: 3:00 - loss: 0.6871 - accuracy: 0.48 - ETA: 2:57 - loss: 0.6778 - accuracy: 0.49 - ETA: 2:54 - loss: 0.6693 - accuracy: 0.50 - ETA: 2:52 - loss: 0.6610 - accuracy: 0.51 - ETA: 2:49 - loss: 0.6526 - accuracy: 0.52 - ETA: 2:47 - loss: 0.6446 - accuracy: 0.52 - ETA: 2:45 - loss: 0.6371 - accuracy: 0.53 - ETA: 2:43 - loss: 0.6306 - accuracy: 0.53 - ETA: 2:41 - loss: 0.6234 - accuracy: 0.54 - ETA: 2:39 - loss: 0.6170 - accuracy: 0.55 - ETA: 2:38 - loss: 0.6106 - accuracy: 0.55 - ETA: 2:36 - loss: 0.6048 - accuracy: 0.56 - ETA: 2:34 - loss: 0.5995 - accuracy: 0.56 - ETA: 2:32 - loss: 0.5944 - accuracy: 0.57 - ETA: 2:31 - loss: 0.5892 - accuracy: 0.58 - ETA: 2:29 - loss: 0.5843 - accuracy: 0.58 - ETA: 2:28 - loss: 0.5793 - accuracy: 0.58 - ETA: 2:27 - loss: 0.5744 - accuracy: 0.59 - ETA: 2:25 - loss: 0.5700 - accuracy: 0.59 - ETA: 2:24 - loss: 0.5653 - accuracy: 0.60 - ETA: 2:23 - loss: 0.5608 - accuracy: 0.60 - ETA: 2:21 - loss: 0.5563 - accuracy: 0.60 - ETA: 2:20 - loss: 0.5521 - accuracy: 0.61 - ETA: 2:19 - loss: 0.5479 - accuracy: 0.61 - ETA: 2:18 - loss: 0.5436 - accuracy: 0.61 - ETA: 2:17 - loss: 0.5396 - accuracy: 0.61 - ETA: 2:16 - loss: 0.5359 - accuracy: 0.62 - ETA: 2:14 - loss: 0.5322 - accuracy: 0.62 - ETA: 2:13 - loss: 0.5285 - accuracy: 0.62 - ETA: 2:12 - loss: 0.5248 - accuracy: 0.63 - ETA: 2:11 - loss: 0.5212 - accuracy: 0.63 - ETA: 2:10 - loss: 0.5177 - accuracy: 0.63 - ETA: 2:09 - loss: 0.5143 - accuracy: 0.63 - ETA: 2:08 - loss: 0.5109 - accuracy: 0.64 - ETA: 2:07 - loss: 0.5090 - accuracy: 0.64 - ETA: 2:06 - loss: 0.5067 - accuracy: 0.64 - ETA: 2:05 - loss: 0.5043 - accuracy: 0.64 - ETA: 2:04 - loss: 0.5015 - accuracy: 0.64 - ETA: 2:04 - loss: 0.4988 - accuracy: 0.64 - ETA: 2:03 - loss: 0.4960 - accuracy: 0.65 - ETA: 2:02 - loss: 0.4931 - accuracy: 0.65 - ETA: 2:01 - loss: 0.4903 - accuracy: 0.65 - ETA: 2:00 - loss: 0.4874 - accuracy: 0.65 - ETA: 1:59 - loss: 0.4846 - accuracy: 0.65 - ETA: 1:58 - loss: 0.4820 - accuracy: 0.65 - ETA: 1:57 - loss: 0.4793 - accuracy: 0.66 - ETA: 1:56 - loss: 0.4767 - accuracy: 0.66 - ETA: 1:56 - loss: 0.4740 - accuracy: 0.66 - ETA: 1:55 - loss: 0.4715 - accuracy: 0.66 - ETA: 1:54 - loss: 0.4690 - accuracy: 0.66 - ETA: 1:53 - loss: 0.4666 - accuracy: 0.66 - ETA: 1:52 - loss: 0.4641 - accuracy: 0.66 - ETA: 1:51 - loss: 0.4616 - accuracy: 0.66 - ETA: 1:50 - loss: 0.4593 - accuracy: 0.67 - ETA: 1:50 - loss: 0.4569 - accuracy: 0.67 - ETA: 1:49 - loss: 0.4546 - accuracy: 0.67 - ETA: 1:48 - loss: 0.4523 - accuracy: 0.67 - ETA: 1:47 - loss: 0.4501 - accuracy: 0.67 - ETA: 1:46 - loss: 0.4478 - accuracy: 0.67 - ETA: 1:45 - loss: 0.4456 - accuracy: 0.67 - ETA: 1:45 - loss: 0.4434 - accuracy: 0.67 - ETA: 1:44 - loss: 0.4413 - accuracy: 0.67 - ETA: 1:43 - loss: 0.4392 - accuracy: 0.68 - ETA: 1:42 - loss: 0.4371 - accuracy: 0.68 - ETA: 1:41 - loss: 0.4350 - accuracy: 0.68 - ETA: 1:40 - loss: 0.4329 - accuracy: 0.68 - ETA: 1:40 - loss: 0.4309 - accuracy: 0.68 - ETA: 1:39 - loss: 0.4289 - accuracy: 0.68 - ETA: 1:38 - loss: 0.4270 - accuracy: 0.68 - ETA: 1:37 - loss: 0.4250 - accuracy: 0.68 - ETA: 1:36 - loss: 0.4231 - accuracy: 0.68 - ETA: 1:36 - loss: 0.4212 - accuracy: 0.68 - ETA: 1:35 - loss: 0.4193 - accuracy: 0.68 - ETA: 1:34 - loss: 0.4175 - accuracy: 0.68 - ETA: 1:33 - loss: 0.4156 - accuracy: 0.69 - ETA: 1:32 - loss: 0.4139 - accuracy: 0.69 - ETA: 1:32 - loss: 0.4122 - accuracy: 0.69 - ETA: 1:31 - loss: 0.4105 - accuracy: 0.69 - ETA: 1:30 - loss: 0.4088 - accuracy: 0.69 - ETA: 1:29 - loss: 0.4070 - accuracy: 0.69 - ETA: 1:29 - loss: 0.4054 - accuracy: 0.69 - ETA: 1:28 - loss: 0.4037 - accuracy: 0.69 - ETA: 1:27 - loss: 0.4020 - accuracy: 0.69 - ETA: 1:26 - loss: 0.4004 - accuracy: 0.69 - ETA: 1:26 - loss: 0.3987 - accuracy: 0.69 - ETA: 1:25 - loss: 0.3971 - accuracy: 0.69 - ETA: 1:25 - loss: 0.3955 - accuracy: 0.69 - ETA: 1:24 - loss: 0.3939 - accuracy: 0.69 - ETA: 1:23 - loss: 0.3923 - accuracy: 0.70 - ETA: 1:23 - loss: 0.3908 - accuracy: 0.70 - ETA: 1:22 - loss: 0.3892 - accuracy: 0.70 - ETA: 1:21 - loss: 0.3876 - accuracy: 0.70 - ETA: 1:20 - loss: 0.3861 - accuracy: 0.70 - ETA: 1:20 - loss: 0.3846 - accuracy: 0.70 - ETA: 1:19 - loss: 0.3831 - accuracy: 0.70 - ETA: 1:18 - loss: 0.3816 - accuracy: 0.70 - ETA: 1:17 - loss: 0.3801 - accuracy: 0.70 - ETA: 1:17 - loss: 0.3787 - accuracy: 0.70 - ETA: 1:16 - loss: 0.3772 - accuracy: 0.70 - ETA: 1:15 - loss: 0.3758 - accuracy: 0.70 - ETA: 1:14 - loss: 0.3743 - accuracy: 0.70 - ETA: 1:14 - loss: 0.3729 - accuracy: 0.70 - ETA: 1:13 - loss: 0.3715 - accuracy: 0.70 - ETA: 1:12 - loss: 0.3701 - accuracy: 0.70 - ETA: 1:11 - loss: 0.3687 - accuracy: 0.70 - ETA: 1:11 - loss: 0.3674 - accuracy: 0.70 - ETA: 1:10 - loss: 0.3660 - accuracy: 0.70 - ETA: 1:09 - loss: 0.3646 - accuracy: 0.70 - ETA: 1:09 - loss: 0.3633 - accuracy: 0.70 - ETA: 1:08 - loss: 0.3619 - accuracy: 0.70 - ETA: 1:07 - loss: 0.3606 - accuracy: 0.70 - ETA: 1:06 - loss: 0.3593 - accuracy: 0.70 - ETA: 1:06 - loss: 0.3579 - accuracy: 0.71 - ETA: 1:05 - loss: 0.3567 - accuracy: 0.71 - ETA: 1:04 - loss: 0.3554 - accuracy: 0.71 - ETA: 1:03 - loss: 0.3541 - accuracy: 0.71 - ETA: 1:03 - loss: 0.3528 - accuracy: 0.71 - ETA: 1:02 - loss: 0.3516 - accuracy: 0.71 - ETA: 1:01 - loss: 0.3503 - accuracy: 0.71 - ETA: 1:01 - loss: 0.3491 - accuracy: 0.71 - ETA: 1:00 - loss: 0.3479 - accuracy: 0.71 - ETA: 59s - loss: 0.3466 - accuracy: 0.7122 - ETA: 58s - loss: 0.3454 - accuracy: 0.712 - ETA: 58s - loss: 0.3442 - accuracy: 0.712 - ETA: 57s - loss: 0.3430 - accuracy: 0.713 - ETA: 56s - loss: 0.3418 - accuracy: 0.713 - ETA: 56s - loss: 0.3407 - accuracy: 0.713 - ETA: 55s - loss: 0.3395 - accuracy: 0.714 - ETA: 54s - loss: 0.3383 - accuracy: 0.714 - ETA: 53s - loss: 0.3372 - accuracy: 0.715 - ETA: 53s - loss: 0.3360 - accuracy: 0.715 - ETA: 52s - loss: 0.3349 - accuracy: 0.715 - ETA: 51s - loss: 0.3338 - accuracy: 0.715 - ETA: 51s - loss: 0.3326 - accuracy: 0.716 - ETA: 50s - loss: 0.3315 - accuracy: 0.716 - ETA: 49s - loss: 0.3304 - accuracy: 0.716 - ETA: 48s - loss: 0.3293 - accuracy: 0.717 - ETA: 48s - loss: 0.3282 - accuracy: 0.717 - ETA: 47s - loss: 0.3272 - accuracy: 0.717 - ETA: 46s - loss: 0.3261 - accuracy: 0.717 - ETA: 46s - loss: 0.3250 - accuracy: 0.718 - ETA: 45s - loss: 0.3240 - accuracy: 0.718 - ETA: 44s - loss: 0.3229 - accuracy: 0.718 - ETA: 43s - loss: 0.3219 - accuracy: 0.719 - ETA: 43s - loss: 0.3208 - accuracy: 0.719 - ETA: 42s - loss: 0.3198 - accuracy: 0.719 - ETA: 41s - loss: 0.3188 - accuracy: 0.719 - ETA: 41s - loss: 0.3178 - accuracy: 0.719 - ETA: 40s - loss: 0.3168 - accuracy: 0.720 - ETA: 39s - loss: 0.3158 - accuracy: 0.720 - ETA: 39s - loss: 0.3148 - accuracy: 0.720 - ETA: 38s - loss: 0.3138 - accuracy: 0.720 - ETA: 37s - loss: 0.3129 - accuracy: 0.720 - ETA: 36s - loss: 0.3119 - accuracy: 0.720 - ETA: 36s - loss: 0.3109 - accuracy: 0.721 - ETA: 35s - loss: 0.3100 - accuracy: 0.721 - ETA: 34s - loss: 0.3090 - accuracy: 0.721 - ETA: 34s - loss: 0.3081 - accuracy: 0.721 - ETA: 33s - loss: 0.3072 - accuracy: 0.721 - ETA: 32s - loss: 0.3062 - accuracy: 0.721 - ETA: 32s - loss: 0.3053 - accuracy: 0.722 - ETA: 31s - loss: 0.3044 - accuracy: 0.7223\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4590/4590 [==============================] - ETA: 30s - loss: 0.3035 - accuracy: 0.722 - ETA: 29s - loss: 0.3026 - accuracy: 0.722 - ETA: 29s - loss: 0.3017 - accuracy: 0.722 - ETA: 28s - loss: 0.3008 - accuracy: 0.722 - ETA: 27s - loss: 0.2999 - accuracy: 0.722 - ETA: 27s - loss: 0.2990 - accuracy: 0.723 - ETA: 26s - loss: 0.2982 - accuracy: 0.723 - ETA: 25s - loss: 0.2973 - accuracy: 0.723 - ETA: 25s - loss: 0.2965 - accuracy: 0.723 - ETA: 24s - loss: 0.2956 - accuracy: 0.723 - ETA: 23s - loss: 0.2947 - accuracy: 0.723 - ETA: 23s - loss: 0.2939 - accuracy: 0.723 - ETA: 22s - loss: 0.2931 - accuracy: 0.723 - ETA: 21s - loss: 0.2922 - accuracy: 0.723 - ETA: 21s - loss: 0.2914 - accuracy: 0.723 - ETA: 20s - loss: 0.2906 - accuracy: 0.724 - ETA: 19s - loss: 0.2897 - accuracy: 0.724 - ETA: 19s - loss: 0.2889 - accuracy: 0.724 - ETA: 18s - loss: 0.2881 - accuracy: 0.724 - ETA: 17s - loss: 0.2873 - accuracy: 0.724 - ETA: 16s - loss: 0.2865 - accuracy: 0.725 - ETA: 16s - loss: 0.2857 - accuracy: 0.725 - ETA: 15s - loss: 0.2849 - accuracy: 0.725 - ETA: 14s - loss: 0.2841 - accuracy: 0.725 - ETA: 14s - loss: 0.2833 - accuracy: 0.725 - ETA: 13s - loss: 0.2826 - accuracy: 0.726 - ETA: 12s - loss: 0.2818 - accuracy: 0.726 - ETA: 12s - loss: 0.2810 - accuracy: 0.726 - ETA: 11s - loss: 0.2803 - accuracy: 0.726 - ETA: 10s - loss: 0.2795 - accuracy: 0.726 - ETA: 10s - loss: 0.2787 - accuracy: 0.726 - ETA: 9s - loss: 0.2780 - accuracy: 0.726 - ETA: 8s - loss: 0.2773 - accuracy: 0.72 - ETA: 7s - loss: 0.2765 - accuracy: 0.72 - ETA: 7s - loss: 0.2758 - accuracy: 0.72 - ETA: 6s - loss: 0.2750 - accuracy: 0.72 - ETA: 5s - loss: 0.2743 - accuracy: 0.72 - ETA: 5s - loss: 0.2736 - accuracy: 0.72 - ETA: 4s - loss: 0.2729 - accuracy: 0.72 - ETA: 3s - loss: 0.2721 - accuracy: 0.72 - ETA: 3s - loss: 0.2714 - accuracy: 0.72 - ETA: 2s - loss: 0.2707 - accuracy: 0.72 - ETA: 1s - loss: 0.2700 - accuracy: 0.72 - ETA: 1s - loss: 0.2693 - accuracy: 0.72 - ETA: 0s - loss: 0.2686 - accuracy: 0.72 - 165s 36ms/step - loss: 0.2683 - accuracy: 0.7289 - val_loss: 0.1399 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13992, saving model to model_weighted_1.h5\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3720/4590 [=======================>......] - ETA: 3:00 - loss: 0.1090 - accuracy: 0.80 - ETA: 3:04 - loss: 0.1099 - accuracy: 0.78 - ETA: 3:06 - loss: 0.1102 - accuracy: 0.78 - ETA: 3:06 - loss: 0.1098 - accuracy: 0.77 - ETA: 3:06 - loss: 0.1097 - accuracy: 0.76 - ETA: 3:04 - loss: 0.1092 - accuracy: 0.77 - ETA: 3:02 - loss: 0.1088 - accuracy: 0.76 - ETA: 3:02 - loss: 0.1084 - accuracy: 0.76 - ETA: 3:06 - loss: 0.1081 - accuracy: 0.76 - ETA: 3:07 - loss: 0.1079 - accuracy: 0.76 - ETA: 3:07 - loss: 0.1076 - accuracy: 0.76 - ETA: 3:07 - loss: 0.1072 - accuracy: 0.76 - ETA: 3:06 - loss: 0.1069 - accuracy: 0.76 - ETA: 3:04 - loss: 0.1067 - accuracy: 0.76 - ETA: 3:03 - loss: 0.1064 - accuracy: 0.76 - ETA: 3:03 - loss: 0.1061 - accuracy: 0.76 - ETA: 3:02 - loss: 0.1058 - accuracy: 0.76 - ETA: 3:01 - loss: 0.1055 - accuracy: 0.76 - ETA: 3:00 - loss: 0.1053 - accuracy: 0.76 - ETA: 2:59 - loss: 0.1050 - accuracy: 0.76 - ETA: 2:58 - loss: 0.1047 - accuracy: 0.76 - ETA: 2:59 - loss: 0.1044 - accuracy: 0.76 - ETA: 2:59 - loss: 0.1042 - accuracy: 0.76 - ETA: 2:58 - loss: 0.1039 - accuracy: 0.76 - ETA: 2:57 - loss: 0.1036 - accuracy: 0.76 - ETA: 2:56 - loss: 0.1034 - accuracy: 0.76 - ETA: 2:55 - loss: 0.1032 - accuracy: 0.76 - ETA: 2:54 - loss: 0.1029 - accuracy: 0.76 - ETA: 2:54 - loss: 0.1027 - accuracy: 0.76 - ETA: 2:53 - loss: 0.1024 - accuracy: 0.76 - ETA: 2:52 - loss: 0.1022 - accuracy: 0.76 - ETA: 2:55 - loss: 0.1019 - accuracy: 0.76 - ETA: 2:54 - loss: 0.1017 - accuracy: 0.76 - ETA: 2:53 - loss: 0.1015 - accuracy: 0.76 - ETA: 2:52 - loss: 0.1012 - accuracy: 0.76 - ETA: 2:52 - loss: 0.1009 - accuracy: 0.76 - ETA: 2:51 - loss: 0.1007 - accuracy: 0.76 - ETA: 2:50 - loss: 0.1005 - accuracy: 0.76 - ETA: 2:50 - loss: 0.1003 - accuracy: 0.76 - ETA: 2:49 - loss: 0.1001 - accuracy: 0.76 - ETA: 2:48 - loss: 0.0998 - accuracy: 0.76 - ETA: 2:47 - loss: 0.0996 - accuracy: 0.76 - ETA: 2:46 - loss: 0.0994 - accuracy: 0.76 - ETA: 2:45 - loss: 0.0991 - accuracy: 0.76 - ETA: 2:44 - loss: 0.0989 - accuracy: 0.76 - ETA: 2:43 - loss: 0.0987 - accuracy: 0.76 - ETA: 2:43 - loss: 0.0985 - accuracy: 0.76 - ETA: 2:42 - loss: 0.0982 - accuracy: 0.76 - ETA: 2:41 - loss: 0.0980 - accuracy: 0.76 - ETA: 2:41 - loss: 0.0978 - accuracy: 0.76 - ETA: 2:40 - loss: 0.0976 - accuracy: 0.76 - ETA: 2:39 - loss: 0.0974 - accuracy: 0.76 - ETA: 2:38 - loss: 0.0972 - accuracy: 0.76 - ETA: 2:37 - loss: 0.0969 - accuracy: 0.76 - ETA: 2:36 - loss: 0.0967 - accuracy: 0.76 - ETA: 2:35 - loss: 0.0965 - accuracy: 0.76 - ETA: 2:34 - loss: 0.0963 - accuracy: 0.76 - ETA: 2:33 - loss: 0.0961 - accuracy: 0.76 - ETA: 2:32 - loss: 0.0959 - accuracy: 0.76 - ETA: 2:31 - loss: 0.0956 - accuracy: 0.76 - ETA: 2:30 - loss: 0.0954 - accuracy: 0.76 - ETA: 2:29 - loss: 0.0952 - accuracy: 0.76 - ETA: 2:29 - loss: 0.0950 - accuracy: 0.76 - ETA: 2:28 - loss: 0.0948 - accuracy: 0.76 - ETA: 2:27 - loss: 0.0946 - accuracy: 0.76 - ETA: 2:26 - loss: 0.0944 - accuracy: 0.76 - ETA: 2:25 - loss: 0.0942 - accuracy: 0.76 - ETA: 2:24 - loss: 0.0940 - accuracy: 0.76 - ETA: 2:23 - loss: 0.0938 - accuracy: 0.76 - ETA: 2:22 - loss: 0.0936 - accuracy: 0.76 - ETA: 2:21 - loss: 0.0934 - accuracy: 0.76 - ETA: 2:20 - loss: 0.0932 - accuracy: 0.76 - ETA: 2:19 - loss: 0.0930 - accuracy: 0.76 - ETA: 2:18 - loss: 0.0928 - accuracy: 0.76 - ETA: 2:17 - loss: 0.0926 - accuracy: 0.76 - ETA: 2:16 - loss: 0.0924 - accuracy: 0.76 - ETA: 2:15 - loss: 0.0922 - accuracy: 0.76 - ETA: 2:14 - loss: 0.0920 - accuracy: 0.76 - ETA: 2:13 - loss: 0.0918 - accuracy: 0.76 - ETA: 2:12 - loss: 0.0917 - accuracy: 0.76 - ETA: 2:11 - loss: 0.0915 - accuracy: 0.76 - ETA: 2:11 - loss: 0.0913 - accuracy: 0.76 - ETA: 2:10 - loss: 0.0911 - accuracy: 0.76 - ETA: 2:09 - loss: 0.0909 - accuracy: 0.76 - ETA: 2:08 - loss: 0.0907 - accuracy: 0.76 - ETA: 2:07 - loss: 0.0905 - accuracy: 0.76 - ETA: 2:06 - loss: 0.0903 - accuracy: 0.76 - ETA: 2:05 - loss: 0.0901 - accuracy: 0.76 - ETA: 2:04 - loss: 0.0899 - accuracy: 0.76 - ETA: 2:03 - loss: 0.0898 - accuracy: 0.76 - ETA: 2:03 - loss: 0.0896 - accuracy: 0.76 - ETA: 2:02 - loss: 0.0894 - accuracy: 0.76 - ETA: 2:01 - loss: 0.0892 - accuracy: 0.76 - ETA: 2:00 - loss: 0.0890 - accuracy: 0.76 - ETA: 2:00 - loss: 0.0889 - accuracy: 0.76 - ETA: 1:59 - loss: 0.0887 - accuracy: 0.76 - ETA: 1:58 - loss: 0.0885 - accuracy: 0.76 - ETA: 1:58 - loss: 0.0883 - accuracy: 0.76 - ETA: 1:57 - loss: 0.0881 - accuracy: 0.76 - ETA: 1:56 - loss: 0.0880 - accuracy: 0.76 - ETA: 1:55 - loss: 0.0878 - accuracy: 0.76 - ETA: 1:54 - loss: 0.0876 - accuracy: 0.76 - ETA: 1:53 - loss: 0.0874 - accuracy: 0.76 - ETA: 1:53 - loss: 0.0873 - accuracy: 0.76 - ETA: 1:52 - loss: 0.0871 - accuracy: 0.76 - ETA: 1:51 - loss: 0.0869 - accuracy: 0.76 - ETA: 1:50 - loss: 0.0867 - accuracy: 0.76 - ETA: 1:49 - loss: 0.0866 - accuracy: 0.76 - ETA: 1:48 - loss: 0.0864 - accuracy: 0.76 - ETA: 1:47 - loss: 0.0862 - accuracy: 0.76 - ETA: 1:47 - loss: 0.0861 - accuracy: 0.76 - ETA: 1:46 - loss: 0.0859 - accuracy: 0.76 - ETA: 1:45 - loss: 0.0857 - accuracy: 0.76 - ETA: 1:44 - loss: 0.0855 - accuracy: 0.76 - ETA: 1:43 - loss: 0.0854 - accuracy: 0.76 - ETA: 1:42 - loss: 0.0852 - accuracy: 0.76 - ETA: 1:41 - loss: 0.0850 - accuracy: 0.76 - ETA: 1:40 - loss: 0.0849 - accuracy: 0.76 - ETA: 1:39 - loss: 0.0847 - accuracy: 0.76 - ETA: 1:38 - loss: 0.0846 - accuracy: 0.76 - ETA: 1:37 - loss: 0.0844 - accuracy: 0.76 - ETA: 1:37 - loss: 0.0842 - accuracy: 0.76 - ETA: 1:36 - loss: 0.0841 - accuracy: 0.76 - ETA: 1:35 - loss: 0.0839 - accuracy: 0.76 - ETA: 1:34 - loss: 0.0837 - accuracy: 0.76 - ETA: 1:33 - loss: 0.0836 - accuracy: 0.76 - ETA: 1:32 - loss: 0.0834 - accuracy: 0.76 - ETA: 1:31 - loss: 0.0833 - accuracy: 0.76 - ETA: 1:30 - loss: 0.0831 - accuracy: 0.76 - ETA: 1:29 - loss: 0.0829 - accuracy: 0.76 - ETA: 1:28 - loss: 0.0828 - accuracy: 0.76 - ETA: 1:27 - loss: 0.0826 - accuracy: 0.76 - ETA: 1:26 - loss: 0.0825 - accuracy: 0.76 - ETA: 1:25 - loss: 0.0823 - accuracy: 0.76 - ETA: 1:24 - loss: 0.0822 - accuracy: 0.76 - ETA: 1:23 - loss: 0.0820 - accuracy: 0.76 - ETA: 1:22 - loss: 0.0819 - accuracy: 0.76 - ETA: 1:21 - loss: 0.0817 - accuracy: 0.76 - ETA: 1:20 - loss: 0.0816 - accuracy: 0.76 - ETA: 1:19 - loss: 0.0814 - accuracy: 0.76 - ETA: 1:18 - loss: 0.0812 - accuracy: 0.76 - ETA: 1:17 - loss: 0.0811 - accuracy: 0.76 - ETA: 1:16 - loss: 0.0809 - accuracy: 0.76 - ETA: 1:15 - loss: 0.0808 - accuracy: 0.76 - ETA: 1:14 - loss: 0.0806 - accuracy: 0.76 - ETA: 1:13 - loss: 0.0805 - accuracy: 0.76 - ETA: 1:12 - loss: 0.0803 - accuracy: 0.76 - ETA: 1:11 - loss: 0.0802 - accuracy: 0.76 - ETA: 1:10 - loss: 0.0800 - accuracy: 0.76 - ETA: 1:09 - loss: 0.0799 - accuracy: 0.76 - ETA: 1:08 - loss: 0.0797 - accuracy: 0.76 - ETA: 1:08 - loss: 0.0796 - accuracy: 0.76 - ETA: 1:07 - loss: 0.0794 - accuracy: 0.76 - ETA: 1:06 - loss: 0.0793 - accuracy: 0.76 - ETA: 1:05 - loss: 0.0792 - accuracy: 0.76 - ETA: 1:04 - loss: 0.0790 - accuracy: 0.76 - ETA: 1:03 - loss: 0.0789 - accuracy: 0.76 - ETA: 1:02 - loss: 0.0787 - accuracy: 0.76 - ETA: 1:01 - loss: 0.0786 - accuracy: 0.76 - ETA: 1:00 - loss: 0.0784 - accuracy: 0.76 - ETA: 59s - loss: 0.0783 - accuracy: 0.7602 - ETA: 58s - loss: 0.0782 - accuracy: 0.760 - ETA: 57s - loss: 0.0780 - accuracy: 0.759 - ETA: 56s - loss: 0.0779 - accuracy: 0.760 - ETA: 56s - loss: 0.0777 - accuracy: 0.760 - ETA: 55s - loss: 0.0776 - accuracy: 0.760 - ETA: 54s - loss: 0.0774 - accuracy: 0.760 - ETA: 53s - loss: 0.0773 - accuracy: 0.760 - ETA: 52s - loss: 0.0772 - accuracy: 0.760 - ETA: 51s - loss: 0.0770 - accuracy: 0.760 - ETA: 50s - loss: 0.0769 - accuracy: 0.760 - ETA: 49s - loss: 0.0768 - accuracy: 0.760 - ETA: 48s - loss: 0.0766 - accuracy: 0.760 - ETA: 47s - loss: 0.0765 - accuracy: 0.760 - ETA: 46s - loss: 0.0764 - accuracy: 0.759 - ETA: 46s - loss: 0.0762 - accuracy: 0.760 - ETA: 45s - loss: 0.0761 - accuracy: 0.760 - ETA: 44s - loss: 0.0759 - accuracy: 0.759 - ETA: 43s - loss: 0.0758 - accuracy: 0.760 - ETA: 42s - loss: 0.0757 - accuracy: 0.760 - ETA: 41s - loss: 0.0755 - accuracy: 0.760 - ETA: 40s - loss: 0.0754 - accuracy: 0.760 - ETA: 39s - loss: 0.0753 - accuracy: 0.760 - ETA: 38s - loss: 0.0752 - accuracy: 0.760 - ETA: 38s - loss: 0.0750 - accuracy: 0.760 - ETA: 37s - loss: 0.0749 - accuracy: 0.7603"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4590/4590 [==============================] - ETA: 36s - loss: 0.0748 - accuracy: 0.760 - ETA: 35s - loss: 0.0746 - accuracy: 0.760 - ETA: 34s - loss: 0.0745 - accuracy: 0.760 - ETA: 33s - loss: 0.0744 - accuracy: 0.760 - ETA: 32s - loss: 0.0742 - accuracy: 0.759 - ETA: 31s - loss: 0.0741 - accuracy: 0.759 - ETA: 30s - loss: 0.0740 - accuracy: 0.759 - ETA: 30s - loss: 0.0739 - accuracy: 0.759 - ETA: 29s - loss: 0.0737 - accuracy: 0.759 - ETA: 28s - loss: 0.0736 - accuracy: 0.759 - ETA: 27s - loss: 0.0735 - accuracy: 0.759 - ETA: 26s - loss: 0.0734 - accuracy: 0.759 - ETA: 25s - loss: 0.0732 - accuracy: 0.759 - ETA: 24s - loss: 0.0731 - accuracy: 0.759 - ETA: 24s - loss: 0.0730 - accuracy: 0.760 - ETA: 23s - loss: 0.0729 - accuracy: 0.760 - ETA: 22s - loss: 0.0727 - accuracy: 0.760 - ETA: 21s - loss: 0.0726 - accuracy: 0.760 - ETA: 20s - loss: 0.0725 - accuracy: 0.759 - ETA: 19s - loss: 0.0724 - accuracy: 0.759 - ETA: 18s - loss: 0.0722 - accuracy: 0.759 - ETA: 18s - loss: 0.0721 - accuracy: 0.759 - ETA: 17s - loss: 0.0720 - accuracy: 0.759 - ETA: 16s - loss: 0.0719 - accuracy: 0.759 - ETA: 15s - loss: 0.0718 - accuracy: 0.759 - ETA: 14s - loss: 0.0716 - accuracy: 0.758 - ETA: 13s - loss: 0.0715 - accuracy: 0.758 - ETA: 12s - loss: 0.0714 - accuracy: 0.758 - ETA: 12s - loss: 0.0713 - accuracy: 0.758 - ETA: 11s - loss: 0.0712 - accuracy: 0.758 - ETA: 10s - loss: 0.0711 - accuracy: 0.758 - ETA: 9s - loss: 0.0709 - accuracy: 0.759 - ETA: 8s - loss: 0.0708 - accuracy: 0.75 - ETA: 7s - loss: 0.0707 - accuracy: 0.75 - ETA: 7s - loss: 0.0706 - accuracy: 0.75 - ETA: 6s - loss: 0.0705 - accuracy: 0.75 - ETA: 5s - loss: 0.0704 - accuracy: 0.75 - ETA: 4s - loss: 0.0702 - accuracy: 0.75 - ETA: 3s - loss: 0.0701 - accuracy: 0.75 - ETA: 2s - loss: 0.0700 - accuracy: 0.75 - ETA: 2s - loss: 0.0699 - accuracy: 0.75 - ETA: 1s - loss: 0.0698 - accuracy: 0.75 - ETA: 0s - loss: 0.0697 - accuracy: 0.75 - 195s 42ms/step - loss: 0.0696 - accuracy: 0.7590 - val_loss: 0.0447 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13992 to 0.04470, saving model to model_weighted_1.h5\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3720/4590 [=======================>......] - ETA: 2:39 - loss: 0.0434 - accuracy: 0.76 - ETA: 2:45 - loss: 0.0431 - accuracy: 0.77 - ETA: 2:47 - loss: 0.0431 - accuracy: 0.77 - ETA: 2:45 - loss: 0.0431 - accuracy: 0.76 - ETA: 2:44 - loss: 0.0430 - accuracy: 0.77 - ETA: 2:44 - loss: 0.0429 - accuracy: 0.77 - ETA: 2:42 - loss: 0.0429 - accuracy: 0.77 - ETA: 2:42 - loss: 0.0429 - accuracy: 0.76 - ETA: 2:41 - loss: 0.0428 - accuracy: 0.76 - ETA: 2:39 - loss: 0.0428 - accuracy: 0.76 - ETA: 2:39 - loss: 0.0428 - accuracy: 0.76 - ETA: 2:38 - loss: 0.0427 - accuracy: 0.76 - ETA: 2:37 - loss: 0.0426 - accuracy: 0.76 - ETA: 2:36 - loss: 0.0426 - accuracy: 0.76 - ETA: 2:35 - loss: 0.0425 - accuracy: 0.76 - ETA: 2:35 - loss: 0.0424 - accuracy: 0.76 - ETA: 2:34 - loss: 0.0424 - accuracy: 0.76 - ETA: 2:33 - loss: 0.0423 - accuracy: 0.76 - ETA: 2:32 - loss: 0.0423 - accuracy: 0.75 - ETA: 2:32 - loss: 0.0422 - accuracy: 0.75 - ETA: 2:31 - loss: 0.0421 - accuracy: 0.75 - ETA: 2:31 - loss: 0.0421 - accuracy: 0.75 - ETA: 2:30 - loss: 0.0420 - accuracy: 0.75 - ETA: 2:30 - loss: 0.0420 - accuracy: 0.75 - ETA: 2:29 - loss: 0.0419 - accuracy: 0.75 - ETA: 2:28 - loss: 0.0418 - accuracy: 0.75 - ETA: 2:27 - loss: 0.0418 - accuracy: 0.75 - ETA: 2:26 - loss: 0.0417 - accuracy: 0.75 - ETA: 2:26 - loss: 0.0416 - accuracy: 0.75 - ETA: 2:26 - loss: 0.0416 - accuracy: 0.75 - ETA: 2:25 - loss: 0.0415 - accuracy: 0.75 - ETA: 2:25 - loss: 0.0414 - accuracy: 0.75 - ETA: 2:24 - loss: 0.0414 - accuracy: 0.75 - ETA: 2:23 - loss: 0.0413 - accuracy: 0.75 - ETA: 2:23 - loss: 0.0413 - accuracy: 0.75 - ETA: 2:22 - loss: 0.0412 - accuracy: 0.75 - ETA: 2:21 - loss: 0.0411 - accuracy: 0.75 - ETA: 2:20 - loss: 0.0410 - accuracy: 0.75 - ETA: 2:19 - loss: 0.0410 - accuracy: 0.75 - ETA: 2:19 - loss: 0.0409 - accuracy: 0.75 - ETA: 2:18 - loss: 0.0409 - accuracy: 0.75 - ETA: 2:17 - loss: 0.0408 - accuracy: 0.75 - ETA: 2:17 - loss: 0.0407 - accuracy: 0.75 - ETA: 2:16 - loss: 0.0407 - accuracy: 0.75 - ETA: 2:15 - loss: 0.0406 - accuracy: 0.75 - ETA: 2:14 - loss: 0.0405 - accuracy: 0.75 - ETA: 2:14 - loss: 0.0405 - accuracy: 0.75 - ETA: 2:13 - loss: 0.0404 - accuracy: 0.75 - ETA: 2:12 - loss: 0.0404 - accuracy: 0.75 - ETA: 2:11 - loss: 0.0403 - accuracy: 0.75 - ETA: 2:10 - loss: 0.0403 - accuracy: 0.75 - ETA: 2:10 - loss: 0.0402 - accuracy: 0.75 - ETA: 2:09 - loss: 0.0401 - accuracy: 0.75 - ETA: 2:08 - loss: 0.0401 - accuracy: 0.75 - ETA: 2:07 - loss: 0.0400 - accuracy: 0.75 - ETA: 2:07 - loss: 0.0400 - accuracy: 0.75 - ETA: 2:06 - loss: 0.0399 - accuracy: 0.75 - ETA: 2:05 - loss: 0.0398 - accuracy: 0.75 - ETA: 2:04 - loss: 0.0398 - accuracy: 0.75 - ETA: 2:04 - loss: 0.0397 - accuracy: 0.75 - ETA: 2:03 - loss: 0.0397 - accuracy: 0.75 - ETA: 2:02 - loss: 0.0396 - accuracy: 0.75 - ETA: 2:01 - loss: 0.0395 - accuracy: 0.75 - ETA: 2:01 - loss: 0.0395 - accuracy: 0.75 - ETA: 2:00 - loss: 0.0394 - accuracy: 0.75 - ETA: 1:59 - loss: 0.0394 - accuracy: 0.75 - ETA: 1:58 - loss: 0.0393 - accuracy: 0.75 - ETA: 1:58 - loss: 0.0392 - accuracy: 0.75 - ETA: 1:57 - loss: 0.0392 - accuracy: 0.75 - ETA: 1:56 - loss: 0.0391 - accuracy: 0.75 - ETA: 1:55 - loss: 0.0391 - accuracy: 0.75 - ETA: 1:54 - loss: 0.0390 - accuracy: 0.75 - ETA: 1:54 - loss: 0.0390 - accuracy: 0.75 - ETA: 1:53 - loss: 0.0389 - accuracy: 0.75 - ETA: 1:52 - loss: 0.0389 - accuracy: 0.75 - ETA: 1:51 - loss: 0.0388 - accuracy: 0.75 - ETA: 1:51 - loss: 0.0387 - accuracy: 0.75 - ETA: 1:50 - loss: 0.0387 - accuracy: 0.75 - ETA: 1:49 - loss: 0.0386 - accuracy: 0.75 - ETA: 1:48 - loss: 0.0386 - accuracy: 0.75 - ETA: 1:48 - loss: 0.0385 - accuracy: 0.75 - ETA: 1:47 - loss: 0.0384 - accuracy: 0.75 - ETA: 1:46 - loss: 0.0384 - accuracy: 0.75 - ETA: 1:45 - loss: 0.0383 - accuracy: 0.75 - ETA: 1:45 - loss: 0.0383 - accuracy: 0.75 - ETA: 1:44 - loss: 0.0382 - accuracy: 0.75 - ETA: 1:43 - loss: 0.0382 - accuracy: 0.75 - ETA: 1:42 - loss: 0.0381 - accuracy: 0.75 - ETA: 1:42 - loss: 0.0381 - accuracy: 0.75 - ETA: 1:41 - loss: 0.0380 - accuracy: 0.75 - ETA: 1:40 - loss: 0.0380 - accuracy: 0.75 - ETA: 1:39 - loss: 0.0379 - accuracy: 0.75 - ETA: 1:39 - loss: 0.0378 - accuracy: 0.75 - ETA: 1:38 - loss: 0.0378 - accuracy: 0.75 - ETA: 1:37 - loss: 0.0377 - accuracy: 0.75 - ETA: 1:37 - loss: 0.0377 - accuracy: 0.75 - ETA: 1:36 - loss: 0.0376 - accuracy: 0.75 - ETA: 1:35 - loss: 0.0376 - accuracy: 0.75 - ETA: 1:34 - loss: 0.0375 - accuracy: 0.75 - ETA: 1:34 - loss: 0.0375 - accuracy: 0.75 - ETA: 1:33 - loss: 0.0374 - accuracy: 0.75 - ETA: 1:32 - loss: 0.0374 - accuracy: 0.75 - ETA: 1:31 - loss: 0.0373 - accuracy: 0.75 - ETA: 1:31 - loss: 0.0373 - accuracy: 0.75 - ETA: 1:30 - loss: 0.0372 - accuracy: 0.75 - ETA: 1:29 - loss: 0.0372 - accuracy: 0.75 - ETA: 1:28 - loss: 0.0371 - accuracy: 0.75 - ETA: 1:28 - loss: 0.0371 - accuracy: 0.75 - ETA: 1:27 - loss: 0.0370 - accuracy: 0.75 - ETA: 1:26 - loss: 0.0370 - accuracy: 0.75 - ETA: 1:26 - loss: 0.0369 - accuracy: 0.75 - ETA: 1:25 - loss: 0.0369 - accuracy: 0.75 - ETA: 1:24 - loss: 0.0368 - accuracy: 0.75 - ETA: 1:23 - loss: 0.0368 - accuracy: 0.75 - ETA: 1:23 - loss: 0.0367 - accuracy: 0.75 - ETA: 1:22 - loss: 0.0367 - accuracy: 0.75 - ETA: 1:21 - loss: 0.0366 - accuracy: 0.75 - ETA: 1:20 - loss: 0.0366 - accuracy: 0.75 - ETA: 1:20 - loss: 0.0365 - accuracy: 0.75 - ETA: 1:19 - loss: 0.0365 - accuracy: 0.75 - ETA: 1:18 - loss: 0.0364 - accuracy: 0.75 - ETA: 1:17 - loss: 0.0364 - accuracy: 0.75 - ETA: 1:17 - loss: 0.0363 - accuracy: 0.75 - ETA: 1:16 - loss: 0.0363 - accuracy: 0.75 - ETA: 1:15 - loss: 0.0362 - accuracy: 0.75 - ETA: 1:15 - loss: 0.0362 - accuracy: 0.75 - ETA: 1:14 - loss: 0.0361 - accuracy: 0.75 - ETA: 1:13 - loss: 0.0361 - accuracy: 0.75 - ETA: 1:12 - loss: 0.0360 - accuracy: 0.75 - ETA: 1:12 - loss: 0.0360 - accuracy: 0.75 - ETA: 1:11 - loss: 0.0359 - accuracy: 0.75 - ETA: 1:10 - loss: 0.0359 - accuracy: 0.75 - ETA: 1:10 - loss: 0.0358 - accuracy: 0.75 - ETA: 1:09 - loss: 0.0358 - accuracy: 0.75 - ETA: 1:08 - loss: 0.0357 - accuracy: 0.75 - ETA: 1:07 - loss: 0.0357 - accuracy: 0.75 - ETA: 1:07 - loss: 0.0356 - accuracy: 0.75 - ETA: 1:06 - loss: 0.0356 - accuracy: 0.75 - ETA: 1:05 - loss: 0.0355 - accuracy: 0.75 - ETA: 1:04 - loss: 0.0355 - accuracy: 0.75 - ETA: 1:04 - loss: 0.0354 - accuracy: 0.75 - ETA: 1:03 - loss: 0.0354 - accuracy: 0.75 - ETA: 1:02 - loss: 0.0354 - accuracy: 0.75 - ETA: 1:02 - loss: 0.0353 - accuracy: 0.75 - ETA: 1:01 - loss: 0.0353 - accuracy: 0.75 - ETA: 1:00 - loss: 0.0352 - accuracy: 0.75 - ETA: 1:00 - loss: 0.0352 - accuracy: 0.75 - ETA: 59s - loss: 0.0351 - accuracy: 0.7585 - ETA: 58s - loss: 0.0351 - accuracy: 0.758 - ETA: 57s - loss: 0.0350 - accuracy: 0.758 - ETA: 57s - loss: 0.0350 - accuracy: 0.758 - ETA: 56s - loss: 0.0350 - accuracy: 0.758 - ETA: 55s - loss: 0.0349 - accuracy: 0.758 - ETA: 54s - loss: 0.0349 - accuracy: 0.759 - ETA: 54s - loss: 0.0348 - accuracy: 0.758 - ETA: 53s - loss: 0.0348 - accuracy: 0.759 - ETA: 52s - loss: 0.0347 - accuracy: 0.759 - ETA: 52s - loss: 0.0347 - accuracy: 0.759 - ETA: 51s - loss: 0.0346 - accuracy: 0.759 - ETA: 50s - loss: 0.0346 - accuracy: 0.759 - ETA: 49s - loss: 0.0345 - accuracy: 0.759 - ETA: 49s - loss: 0.0345 - accuracy: 0.759 - ETA: 48s - loss: 0.0345 - accuracy: 0.759 - ETA: 47s - loss: 0.0344 - accuracy: 0.759 - ETA: 46s - loss: 0.0344 - accuracy: 0.758 - ETA: 46s - loss: 0.0343 - accuracy: 0.758 - ETA: 45s - loss: 0.0343 - accuracy: 0.758 - ETA: 44s - loss: 0.0343 - accuracy: 0.758 - ETA: 43s - loss: 0.0342 - accuracy: 0.758 - ETA: 43s - loss: 0.0342 - accuracy: 0.758 - ETA: 42s - loss: 0.0341 - accuracy: 0.758 - ETA: 41s - loss: 0.0341 - accuracy: 0.758 - ETA: 40s - loss: 0.0340 - accuracy: 0.758 - ETA: 40s - loss: 0.0340 - accuracy: 0.758 - ETA: 39s - loss: 0.0340 - accuracy: 0.758 - ETA: 38s - loss: 0.0339 - accuracy: 0.758 - ETA: 38s - loss: 0.0339 - accuracy: 0.758 - ETA: 37s - loss: 0.0338 - accuracy: 0.758 - ETA: 36s - loss: 0.0338 - accuracy: 0.757 - ETA: 35s - loss: 0.0338 - accuracy: 0.757 - ETA: 35s - loss: 0.0337 - accuracy: 0.758 - ETA: 34s - loss: 0.0337 - accuracy: 0.758 - ETA: 33s - loss: 0.0336 - accuracy: 0.758 - ETA: 32s - loss: 0.0336 - accuracy: 0.758 - ETA: 32s - loss: 0.0336 - accuracy: 0.758 - ETA: 31s - loss: 0.0335 - accuracy: 0.7581"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4590/4590 [==============================] - ETA: 30s - loss: 0.0335 - accuracy: 0.758 - ETA: 30s - loss: 0.0334 - accuracy: 0.758 - ETA: 29s - loss: 0.0334 - accuracy: 0.758 - ETA: 28s - loss: 0.0334 - accuracy: 0.758 - ETA: 27s - loss: 0.0333 - accuracy: 0.758 - ETA: 27s - loss: 0.0333 - accuracy: 0.758 - ETA: 26s - loss: 0.0332 - accuracy: 0.758 - ETA: 25s - loss: 0.0332 - accuracy: 0.758 - ETA: 24s - loss: 0.0331 - accuracy: 0.758 - ETA: 24s - loss: 0.0331 - accuracy: 0.758 - ETA: 23s - loss: 0.0331 - accuracy: 0.758 - ETA: 22s - loss: 0.0330 - accuracy: 0.758 - ETA: 22s - loss: 0.0330 - accuracy: 0.758 - ETA: 21s - loss: 0.0330 - accuracy: 0.758 - ETA: 20s - loss: 0.0329 - accuracy: 0.758 - ETA: 19s - loss: 0.0329 - accuracy: 0.758 - ETA: 19s - loss: 0.0328 - accuracy: 0.758 - ETA: 18s - loss: 0.0328 - accuracy: 0.758 - ETA: 17s - loss: 0.0328 - accuracy: 0.758 - ETA: 16s - loss: 0.0327 - accuracy: 0.758 - ETA: 16s - loss: 0.0327 - accuracy: 0.758 - ETA: 15s - loss: 0.0326 - accuracy: 0.758 - ETA: 14s - loss: 0.0326 - accuracy: 0.758 - ETA: 14s - loss: 0.0326 - accuracy: 0.758 - ETA: 13s - loss: 0.0325 - accuracy: 0.758 - ETA: 12s - loss: 0.0325 - accuracy: 0.758 - ETA: 11s - loss: 0.0325 - accuracy: 0.758 - ETA: 11s - loss: 0.0324 - accuracy: 0.758 - ETA: 10s - loss: 0.0324 - accuracy: 0.758 - ETA: 9s - loss: 0.0323 - accuracy: 0.758 - ETA: 9s - loss: 0.0323 - accuracy: 0.75 - ETA: 8s - loss: 0.0323 - accuracy: 0.75 - ETA: 7s - loss: 0.0322 - accuracy: 0.75 - ETA: 6s - loss: 0.0322 - accuracy: 0.75 - ETA: 6s - loss: 0.0321 - accuracy: 0.75 - ETA: 5s - loss: 0.0321 - accuracy: 0.75 - ETA: 4s - loss: 0.0321 - accuracy: 0.75 - ETA: 3s - loss: 0.0320 - accuracy: 0.75 - ETA: 3s - loss: 0.0320 - accuracy: 0.75 - ETA: 2s - loss: 0.0320 - accuracy: 0.75 - ETA: 1s - loss: 0.0319 - accuracy: 0.75 - ETA: 1s - loss: 0.0319 - accuracy: 0.75 - ETA: 0s - loss: 0.0319 - accuracy: 0.75 - 170s 37ms/step - loss: 0.0318 - accuracy: 0.7590 - val_loss: 0.0227 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04470 to 0.02270, saving model to model_weighted_1.h5\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, batch_size=20, epochs=3, callbacks=callbacks,\n",
    "                    validation_data=(X_valid, y_valid), class_weight = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
