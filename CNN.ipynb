{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:08:53.842653Z",
     "start_time": "2019-11-15T19:08:50.436107Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:08:54.005140Z",
     "start_time": "2019-11-15T19:08:53.844646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images =  5000\n"
     ]
    }
   ],
   "source": [
    "ids = next(os.walk(\"data/images\"))[2] # list of names all images in the given path\n",
    "ids_m = next(os.walk(\"data/masks\"))[2] # list of names all images in the given path\n",
    "\n",
    "print(\"No. of images = \", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:08:54.010109Z",
     "start_time": "2019-11-15T19:08:54.007112Z"
    }
   },
   "outputs": [],
   "source": [
    "im_width = 32\n",
    "im_height = 32\n",
    "border = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:08:54.018082Z",
     "start_time": "2019-11-15T19:08:54.012100Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:14:53.830816Z",
     "start_time": "2019-11-15T19:09:18.613704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120f1aa50f4c4468b6eb8924b061b1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "    # Load images\n",
    "    img = load_img(\"data/images/\"+id_, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (im_width, im_height, 1), mode = 'constant', preserve_range = True)\n",
    "    # Load masks\n",
    "    mask = img_to_array(load_img(\"data/masks/\"+ id_[:-4] + '.png', grayscale=True))\n",
    "    mask = resize(mask, (im_width, im_height, 1), mode = 'constant', preserve_range = True)\n",
    "    # Save images\n",
    "    X[n] = x_img/255.0\n",
    "    y[n] = mask/255.0\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:14:53.841787Z",
     "start_time": "2019-11-15T19:14:53.832813Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:14:53.864725Z",
     "start_time": "2019-11-15T19:14:53.844779Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:14:55.540658Z",
     "start_time": "2019-11-15T19:14:53.866722Z"
    }
   },
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:14:55.827906Z",
     "start_time": "2019-11-15T19:14:55.542654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   160         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 32)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 4, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 128)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2, 2, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 2, 2, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2, 2, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 128)    295040      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4, 4, 256)    0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 128)    295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 64)     73792       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 128)    0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8, 8, 128)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 64)     73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 16, 16, 32)   18464       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout_7 (Dropout)             (None, 16, 16, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 16)   4624        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 32)   0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 32)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 16)   4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 1)    17          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,179,121\n",
      "Trainable params: 1,177,649\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:18:16.612222Z",
     "start_time": "2019-11-15T19:18:16.606238Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T20:41:16.242351Z",
     "start_time": "2019-11-15T19:18:18.689067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "4500/4500 [==============================] - ETA: 5:16 - loss: 0.8059 - accuracy: 0.01 - ETA: 2:50 - loss: 0.7674 - accuracy: 0.02 - ETA: 2:01 - loss: 0.7313 - accuracy: 0.02 - ETA: 1:36 - loss: 0.7104 - accuracy: 0.02 - ETA: 1:22 - loss: 0.7027 - accuracy: 0.02 - ETA: 1:12 - loss: 0.6938 - accuracy: 0.02 - ETA: 1:05 - loss: 0.6924 - accuracy: 0.02 - ETA: 1:00 - loss: 0.6888 - accuracy: 0.02 - ETA: 56s - loss: 0.6843 - accuracy: 0.0219 - ETA: 52s - loss: 0.6837 - accuracy: 0.020 - ETA: 50s - loss: 0.6846 - accuracy: 0.019 - ETA: 47s - loss: 0.6792 - accuracy: 0.018 - ETA: 45s - loss: 0.6765 - accuracy: 0.018 - ETA: 43s - loss: 0.6734 - accuracy: 0.018 - ETA: 42s - loss: 0.6699 - accuracy: 0.017 - ETA: 42s - loss: 0.6668 - accuracy: 0.019 - ETA: 42s - loss: 0.6660 - accuracy: 0.019 - ETA: 42s - loss: 0.6624 - accuracy: 0.020 - ETA: 42s - loss: 0.6597 - accuracy: 0.020 - ETA: 42s - loss: 0.6582 - accuracy: 0.021 - ETA: 42s - loss: 0.6559 - accuracy: 0.021 - ETA: 42s - loss: 0.6540 - accuracy: 0.023 - ETA: 42s - loss: 0.6526 - accuracy: 0.024 - ETA: 41s - loss: 0.6521 - accuracy: 0.024 - ETA: 41s - loss: 0.6517 - accuracy: 0.025 - ETA: 41s - loss: 0.6510 - accuracy: 0.024 - ETA: 41s - loss: 0.6508 - accuracy: 0.024 - ETA: 40s - loss: 0.6506 - accuracy: 0.024 - ETA: 40s - loss: 0.6500 - accuracy: 0.023 - ETA: 39s - loss: 0.6494 - accuracy: 0.024 - ETA: 39s - loss: 0.6490 - accuracy: 0.024 - ETA: 39s - loss: 0.6481 - accuracy: 0.024 - ETA: 38s - loss: 0.6467 - accuracy: 0.024 - ETA: 38s - loss: 0.6464 - accuracy: 0.024 - ETA: 38s - loss: 0.6456 - accuracy: 0.025 - ETA: 37s - loss: 0.6449 - accuracy: 0.025 - ETA: 37s - loss: 0.6445 - accuracy: 0.024 - ETA: 36s - loss: 0.6443 - accuracy: 0.024 - ETA: 36s - loss: 0.6438 - accuracy: 0.024 - ETA: 35s - loss: 0.6430 - accuracy: 0.024 - ETA: 35s - loss: 0.6428 - accuracy: 0.023 - ETA: 34s - loss: 0.6423 - accuracy: 0.023 - ETA: 34s - loss: 0.6421 - accuracy: 0.023 - ETA: 33s - loss: 0.6414 - accuracy: 0.023 - ETA: 33s - loss: 0.6416 - accuracy: 0.023 - ETA: 33s - loss: 0.6413 - accuracy: 0.023 - ETA: 32s - loss: 0.6410 - accuracy: 0.022 - ETA: 32s - loss: 0.6403 - accuracy: 0.023 - ETA: 31s - loss: 0.6403 - accuracy: 0.023 - ETA: 31s - loss: 0.6404 - accuracy: 0.023 - ETA: 31s - loss: 0.6403 - accuracy: 0.023 - ETA: 30s - loss: 0.6402 - accuracy: 0.022 - ETA: 30s - loss: 0.6394 - accuracy: 0.022 - ETA: 29s - loss: 0.6394 - accuracy: 0.022 - ETA: 29s - loss: 0.6391 - accuracy: 0.022 - ETA: 28s - loss: 0.6388 - accuracy: 0.022 - ETA: 28s - loss: 0.6383 - accuracy: 0.022 - ETA: 28s - loss: 0.6382 - accuracy: 0.022 - ETA: 27s - loss: 0.6377 - accuracy: 0.022 - ETA: 27s - loss: 0.6375 - accuracy: 0.023 - ETA: 26s - loss: 0.6374 - accuracy: 0.022 - ETA: 26s - loss: 0.6371 - accuracy: 0.023 - ETA: 26s - loss: 0.6367 - accuracy: 0.022 - ETA: 25s - loss: 0.6363 - accuracy: 0.023 - ETA: 25s - loss: 0.6361 - accuracy: 0.023 - ETA: 25s - loss: 0.6361 - accuracy: 0.023 - ETA: 24s - loss: 0.6358 - accuracy: 0.023 - ETA: 24s - loss: 0.6357 - accuracy: 0.023 - ETA: 24s - loss: 0.6356 - accuracy: 0.023 - ETA: 23s - loss: 0.6355 - accuracy: 0.023 - ETA: 23s - loss: 0.6357 - accuracy: 0.023 - ETA: 23s - loss: 0.6355 - accuracy: 0.022 - ETA: 22s - loss: 0.6356 - accuracy: 0.022 - ETA: 22s - loss: 0.6352 - accuracy: 0.023 - ETA: 22s - loss: 0.6354 - accuracy: 0.023 - ETA: 21s - loss: 0.6351 - accuracy: 0.023 - ETA: 21s - loss: 0.6348 - accuracy: 0.023 - ETA: 21s - loss: 0.6346 - accuracy: 0.022 - ETA: 20s - loss: 0.6344 - accuracy: 0.023 - ETA: 20s - loss: 0.6345 - accuracy: 0.023 - ETA: 20s - loss: 0.6342 - accuracy: 0.023 - ETA: 19s - loss: 0.6338 - accuracy: 0.023 - ETA: 19s - loss: 0.6336 - accuracy: 0.022 - ETA: 19s - loss: 0.6332 - accuracy: 0.023 - ETA: 18s - loss: 0.6332 - accuracy: 0.023 - ETA: 18s - loss: 0.6330 - accuracy: 0.022 - ETA: 18s - loss: 0.6330 - accuracy: 0.022 - ETA: 17s - loss: 0.6328 - accuracy: 0.023 - ETA: 17s - loss: 0.6328 - accuracy: 0.022 - ETA: 17s - loss: 0.6325 - accuracy: 0.022 - ETA: 16s - loss: 0.6323 - accuracy: 0.022 - ETA: 16s - loss: 0.6321 - accuracy: 0.022 - ETA: 16s - loss: 0.6319 - accuracy: 0.022 - ETA: 15s - loss: 0.6319 - accuracy: 0.022 - ETA: 15s - loss: 0.6317 - accuracy: 0.022 - ETA: 15s - loss: 0.6316 - accuracy: 0.022 - ETA: 14s - loss: 0.6313 - accuracy: 0.022 - ETA: 14s - loss: 0.6312 - accuracy: 0.023 - ETA: 14s - loss: 0.6313 - accuracy: 0.023 - ETA: 13s - loss: 0.6311 - accuracy: 0.023 - ETA: 13s - loss: 0.6310 - accuracy: 0.023 - ETA: 13s - loss: 0.6307 - accuracy: 0.023 - ETA: 12s - loss: 0.6304 - accuracy: 0.023 - ETA: 12s - loss: 0.6302 - accuracy: 0.023 - ETA: 12s - loss: 0.6301 - accuracy: 0.023 - ETA: 11s - loss: 0.6300 - accuracy: 0.023 - ETA: 11s - loss: 0.6299 - accuracy: 0.023 - ETA: 11s - loss: 0.6298 - accuracy: 0.023 - ETA: 10s - loss: 0.6297 - accuracy: 0.023 - ETA: 10s - loss: 0.6294 - accuracy: 0.023 - ETA: 10s - loss: 0.6296 - accuracy: 0.023 - ETA: 9s - loss: 0.6294 - accuracy: 0.023 - ETA: 9s - loss: 0.6294 - accuracy: 0.02 - ETA: 9s - loss: 0.6294 - accuracy: 0.02 - ETA: 8s - loss: 0.6297 - accuracy: 0.02 - ETA: 8s - loss: 0.6297 - accuracy: 0.02 - ETA: 8s - loss: 0.6297 - accuracy: 0.02 - ETA: 7s - loss: 0.6297 - accuracy: 0.02 - ETA: 7s - loss: 0.6295 - accuracy: 0.02 - ETA: 7s - loss: 0.6293 - accuracy: 0.02 - ETA: 6s - loss: 0.6293 - accuracy: 0.02 - ETA: 6s - loss: 0.6290 - accuracy: 0.02 - ETA: 6s - loss: 0.6289 - accuracy: 0.02 - ETA: 5s - loss: 0.6288 - accuracy: 0.02 - ETA: 5s - loss: 0.6287 - accuracy: 0.02 - ETA: 5s - loss: 0.6287 - accuracy: 0.02 - ETA: 4s - loss: 0.6287 - accuracy: 0.02 - ETA: 4s - loss: 0.6288 - accuracy: 0.02 - ETA: 4s - loss: 0.6289 - accuracy: 0.02 - ETA: 3s - loss: 0.6290 - accuracy: 0.02 - ETA: 3s - loss: 0.6290 - accuracy: 0.02 - ETA: 3s - loss: 0.6288 - accuracy: 0.02 - ETA: 2s - loss: 0.6288 - accuracy: 0.02 - ETA: 2s - loss: 0.6287 - accuracy: 0.02 - ETA: 1s - loss: 0.6287 - accuracy: 0.02 - ETA: 1s - loss: 0.6287 - accuracy: 0.02 - ETA: 1s - loss: 0.6287 - accuracy: 0.02 - ETA: 0s - loss: 0.6286 - accuracy: 0.02 - ETA: 0s - loss: 0.6286 - accuracy: 0.02 - ETA: 0s - loss: 0.6285 - accuracy: 0.02 - 50s 11ms/step - loss: 0.6285 - accuracy: 0.0233 - val_loss: 0.6396 - val_accuracy: 0.0174\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63959, saving model to model-tgs-salt.h5\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - ETA: 34s - loss: 0.6231 - accuracy: 0.031 - ETA: 35s - loss: 0.6245 - accuracy: 0.029 - ETA: 36s - loss: 0.6236 - accuracy: 0.022 - ETA: 38s - loss: 0.6211 - accuracy: 0.019 - ETA: 39s - loss: 0.6194 - accuracy: 0.017 - ETA: 40s - loss: 0.6196 - accuracy: 0.021 - ETA: 41s - loss: 0.6238 - accuracy: 0.019 - ETA: 42s - loss: 0.6241 - accuracy: 0.018 - ETA: 41s - loss: 0.6244 - accuracy: 0.018 - ETA: 41s - loss: 0.6255 - accuracy: 0.019 - ETA: 40s - loss: 0.6242 - accuracy: 0.018 - ETA: 40s - loss: 0.6232 - accuracy: 0.017 - ETA: 40s - loss: 0.6249 - accuracy: 0.018 - ETA: 39s - loss: 0.6227 - accuracy: 0.019 - ETA: 39s - loss: 0.6216 - accuracy: 0.019 - ETA: 39s - loss: 0.6220 - accuracy: 0.019 - ETA: 39s - loss: 0.6224 - accuracy: 0.017 - ETA: 39s - loss: 0.6226 - accuracy: 0.019 - ETA: 39s - loss: 0.6231 - accuracy: 0.020 - ETA: 39s - loss: 0.6236 - accuracy: 0.019 - ETA: 39s - loss: 0.6234 - accuracy: 0.020 - ETA: 39s - loss: 0.6229 - accuracy: 0.020 - ETA: 39s - loss: 0.6223 - accuracy: 0.021 - ETA: 38s - loss: 0.6217 - accuracy: 0.022 - ETA: 38s - loss: 0.6222 - accuracy: 0.022 - ETA: 38s - loss: 0.6222 - accuracy: 0.022 - ETA: 37s - loss: 0.6217 - accuracy: 0.023 - ETA: 37s - loss: 0.6221 - accuracy: 0.023 - ETA: 37s - loss: 0.6216 - accuracy: 0.023 - ETA: 37s - loss: 0.6221 - accuracy: 0.023 - ETA: 36s - loss: 0.6216 - accuracy: 0.023 - ETA: 36s - loss: 0.6221 - accuracy: 0.023 - ETA: 36s - loss: 0.6217 - accuracy: 0.022 - ETA: 35s - loss: 0.6218 - accuracy: 0.022 - ETA: 35s - loss: 0.6220 - accuracy: 0.022 - ETA: 35s - loss: 0.6218 - accuracy: 0.022 - ETA: 34s - loss: 0.6221 - accuracy: 0.022 - ETA: 34s - loss: 0.6215 - accuracy: 0.022 - ETA: 35s - loss: 0.6212 - accuracy: 0.023 - ETA: 3:25:07 - loss: 0.6209 - accuracy: 0.023 - ETA: 3:18:09 - loss: 0.6212 - accuracy: 0.022 - ETA: 3:11:30 - loss: 0.6214 - accuracy: 0.022 - ETA: 3:05:10 - loss: 0.6213 - accuracy: 0.022 - ETA: 2:59:08 - loss: 0.6213 - accuracy: 0.022 - ETA: 2:53:21 - loss: 0.6212 - accuracy: 0.022 - ETA: 2:47:49 - loss: 0.6210 - accuracy: 0.022 - ETA: 2:42:31 - loss: 0.6213 - accuracy: 0.021 - ETA: 2:37:27 - loss: 0.6213 - accuracy: 0.021 - ETA: 2:32:34 - loss: 0.6208 - accuracy: 0.021 - ETA: 2:27:54 - loss: 0.6206 - accuracy: 0.022 - ETA: 2:23:24 - loss: 0.6209 - accuracy: 0.021 - ETA: 2:19:05 - loss: 0.6210 - accuracy: 0.021 - ETA: 2:14:55 - loss: 0.6209 - accuracy: 0.021 - ETA: 2:10:55 - loss: 0.6214 - accuracy: 0.021 - ETA: 2:07:04 - loss: 0.6215 - accuracy: 0.021 - ETA: 2:03:20 - loss: 0.6214 - accuracy: 0.021 - ETA: 1:59:45 - loss: 0.6213 - accuracy: 0.021 - ETA: 1:56:17 - loss: 0.6213 - accuracy: 0.021 - ETA: 1:52:56 - loss: 0.6213 - accuracy: 0.022 - ETA: 1:49:42 - loss: 0.6213 - accuracy: 0.022 - ETA: 1:46:34 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:43:32 - loss: 0.6217 - accuracy: 0.021 - ETA: 1:40:36 - loss: 0.6216 - accuracy: 0.021 - ETA: 1:37:45 - loss: 0.6217 - accuracy: 0.021 - ETA: 1:35:00 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:32:19 - loss: 0.6219 - accuracy: 0.021 - ETA: 1:29:44 - loss: 0.6220 - accuracy: 0.021 - ETA: 1:27:13 - loss: 0.6219 - accuracy: 0.021 - ETA: 1:24:46 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:22:24 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:20:05 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:17:50 - loss: 0.6217 - accuracy: 0.021 - ETA: 1:15:40 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:13:32 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:11:28 - loss: 0.6219 - accuracy: 0.021 - ETA: 1:09:27 - loss: 0.6217 - accuracy: 0.021 - ETA: 1:07:30 - loss: 0.6220 - accuracy: 0.021 - ETA: 1:05:35 - loss: 0.6218 - accuracy: 0.021 - ETA: 1:03:43 - loss: 0.6219 - accuracy: 0.021 - ETA: 1:01:54 - loss: 0.6219 - accuracy: 0.021 - ETA: 1:00:08 - loss: 0.6218 - accuracy: 0.021 - ETA: 58:25 - loss: 0.6214 - accuracy: 0.0217  - ETA: 56:43 - loss: 0.6214 - accuracy: 0.021 - ETA: 55:05 - loss: 0.6213 - accuracy: 0.021 - ETA: 53:28 - loss: 0.6211 - accuracy: 0.021 - ETA: 51:54 - loss: 0.6211 - accuracy: 0.021 - ETA: 50:22 - loss: 0.6212 - accuracy: 0.022 - ETA: 48:52 - loss: 0.6211 - accuracy: 0.021 - ETA: 47:24 - loss: 0.6210 - accuracy: 0.021 - ETA: 45:58 - loss: 0.6211 - accuracy: 0.021 - ETA: 44:34 - loss: 0.6210 - accuracy: 0.021 - ETA: 43:12 - loss: 0.6209 - accuracy: 0.021 - ETA: 41:51 - loss: 0.6208 - accuracy: 0.021 - ETA: 40:32 - loss: 0.6206 - accuracy: 0.021 - ETA: 39:15 - loss: 0.6206 - accuracy: 0.022 - ETA: 38:00 - loss: 0.6207 - accuracy: 0.022 - ETA: 36:46 - loss: 0.6206 - accuracy: 0.022 - ETA: 35:33 - loss: 0.6206 - accuracy: 0.022 - ETA: 34:22 - loss: 0.6204 - accuracy: 0.022 - ETA: 33:13 - loss: 0.6204 - accuracy: 0.022 - ETA: 32:04 - loss: 0.6204 - accuracy: 0.022 - ETA: 30:57 - loss: 0.6202 - accuracy: 0.022 - ETA: 29:52 - loss: 0.6204 - accuracy: 0.022 - ETA: 28:47 - loss: 0.6205 - accuracy: 0.022 - ETA: 27:44 - loss: 0.6205 - accuracy: 0.022 - ETA: 26:42 - loss: 0.6205 - accuracy: 0.022 - ETA: 25:42 - loss: 0.6206 - accuracy: 0.022 - ETA: 24:42 - loss: 0.6206 - accuracy: 0.022 - ETA: 23:43 - loss: 0.6206 - accuracy: 0.022 - ETA: 22:46 - loss: 0.6204 - accuracy: 0.022 - ETA: 21:49 - loss: 0.6203 - accuracy: 0.022 - ETA: 20:54 - loss: 0.6201 - accuracy: 0.022 - ETA: 19:59 - loss: 0.6201 - accuracy: 0.022 - ETA: 19:06 - loss: 0.6202 - accuracy: 0.022 - ETA: 18:13 - loss: 0.6200 - accuracy: 0.022 - ETA: 17:22 - loss: 0.6200 - accuracy: 0.022 - ETA: 16:31 - loss: 0.6199 - accuracy: 0.022 - ETA: 15:41 - loss: 0.6199 - accuracy: 0.022 - ETA: 14:52 - loss: 0.6198 - accuracy: 0.022 - ETA: 14:03 - loss: 0.6198 - accuracy: 0.022 - ETA: 13:16 - loss: 0.6195 - accuracy: 0.023 - ETA: 12:29 - loss: 0.6194 - accuracy: 0.023 - ETA: 11:43 - loss: 0.6196 - accuracy: 0.023 - ETA: 10:58 - loss: 0.6196 - accuracy: 0.023 - ETA: 10:13 - loss: 0.6197 - accuracy: 0.023 - ETA: 9:29 - loss: 0.6195 - accuracy: 0.023 - ETA: 8:46 - loss: 0.6195 - accuracy: 0.02 - ETA: 8:04 - loss: 0.6193 - accuracy: 0.02 - ETA: 7:22 - loss: 0.6192 - accuracy: 0.02 - ETA: 6:41 - loss: 0.6193 - accuracy: 0.02 - ETA: 6:00 - loss: 0.6193 - accuracy: 0.02 - ETA: 5:21 - loss: 0.6194 - accuracy: 0.02 - ETA: 4:41 - loss: 0.6193 - accuracy: 0.02 - ETA: 4:02 - loss: 0.6193 - accuracy: 0.02 - ETA: 3:24 - loss: 0.6192 - accuracy: 0.02 - ETA: 2:47 - loss: 0.6192 - accuracy: 0.02 - ETA: 2:10 - loss: 0.6193 - accuracy: 0.02 - ETA: 1:33 - loss: 0.6195 - accuracy: 0.02 - ETA: 57s - loss: 0.6194 - accuracy: 0.0234 - ETA: 21s - loss: 0.6195 - accuracy: 0.023 - 4918s 1s/step - loss: 0.6195 - accuracy: 0.0234 - val_loss: 0.6145 - val_accuracy: 0.0206\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63959 to 0.61451, saving model to model-tgs-salt.h5\n",
      "Epoch 3/5\n",
      "  96/4500 [..............................] - ETA: 1:53 - loss: 0.6130 - accuracy: 0.02 - ETA: 1:54 - loss: 0.6221 - accuracy: 0.01 - ETA: 1:46 - loss: 0.6246 - accuracy: 0.0188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1868b64a3855>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m results = model.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=callbacks,\\\n\u001b[1;32m----> 2\u001b[1;33m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mechamt\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, batch_size=32, epochs=5, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T19:06:32.303607Z",
     "start_time": "2019-11-15T19:06:22.676186Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
